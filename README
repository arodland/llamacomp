Needs the [llama.cpp](https://github.com/ggerganov/llama.cpp) HTTP server running, e.g.

```
./server -ngl 33 -c 2048 -m models/llama-3-8b.Q5_K_M.gguf
```
